% Activate the following line by filling in the right side. If for example the name of the root file is Main.tex, write
% "...root = Main.tex" if the chapter file is in the same directory, and "...root = ../Main.tex" if the chapter is in a subdirectory.
 
% !TEX root = ../thesis.tex

\chapter{Introduction}

\section{Motivation}

This work concerns the interaction between anatomy, medical image acquisition and parameter estimation. Though these are broad and disparate topics in isolation, a common thread can be drawn between them as follows. Firstly, anatomy impacts upon image acquisition. This is because volumetric imaging techniques of limited spatial resolution struggle to capture complex anatomies such as the cerebral cortex, which gives rise to a number of artefacts within the resultant data. In turn, these anatomically-induced artefacts impact upon parameter estimation. This is because estimation techniques may not account for, or be aware of, the existence of such artefacts, which leads to the introduction of confound or bias into the results. One such example is the partial volume effect\footnote{Often also referred to in the plural form, \textit{partial volume effects}; both are used in this work.} (PVE), a focus of this work. 

The central premise of this work is that volumetric analysis strategies often treat complex anatomies as an afterthought. Though the challenge posed by PVE is widely acknowledged, strategies that attempt to deal with it (partial volume effect correction, PVEc) do not address the fundamental issue: the volume space is poorly-suited to the anatomy in question. Rather, the dominant approach is to obtain an explicitly volumetric representation of the problematic anatomy (partial volume estimates) and then attempt to mitigate the issues in that same space. The poor reputation of PVEc within the status quo is demonstrated by the fact that there is currently no firm consensus across modalities on whether it should be performed by default; on how it should be performed; or even on whether it is beneficial to do so. 

The alternative approach developed in this work is to give anatomy primacy in the estimation process. Rather than relying upon an explicitly volumetric representation of anatomy, the estimation is instead performed directly in the space that is most suited to the anatomy. For the cortex, this means it is performed in a surface-based manner directly from the data with no intermediate steps. For the subcortex, a conventional volumetric approach is retained. The most consequential ramification of this `anatomy-first' approach is that PVE are naturally accounted for by default and hence PVEc becomes intrinsic.  

This approach draws considerable inspiration from the existing body of work on surface-based methods for the cortex. Though the analysis of surface-derived structural features (for example, cortical thickness and folding) is very well established, the analysis of function or physiology on the surface is somewhat more recent, particularly when using volumetric magnetic resonance imaging (MRI) data. Nevertheless, the literature demonstrates that surface methods can provide substantial benefits in a number of different ways. For example, the aforementioned metrics of cortical thickness and folding provide biomarkers of neurodegeneration and development, respectively. Surface-based approaches to registration offer an improved ability to identify areas of functional correspondence between subjects, which in turn increases the power of multi-subject studies. Many of the current trends in surface-based analysis, as well examples of the benefits, can be found within the work performed by the Human Connectome Project (HCP), a large multi-centre study into brain development, function and ageing. In particular, the HCP has developed and published a number of processing pipelines that enable the surface-based analysis of blood oxygen level dependent (BOLD) volumetric MRI data. 

One important omission to the surface-based approach espoused by the HCP is that it does not address the question of how to analyse data that does not relate solely to the cortex. In large part, this is justified by the nature of the BOLD modality, for which the HCP assume that subcortical white matter contributes only noise signal that can be regressed out at an early stage. This would not be appropriate for arterial spin labelling (ASL) MRI, which measures a signal of interest - indicative of perfusion - in both the cortex and subcortex. In that situation, one would want an analysis strategy that treated both the cortex and subcortex in an optimal manner, without making any simplifying assumptions that negatively impact either. 

Therein lies the key contribution made by this work: a framework for combined surface-based and volumetric perfusion estimation from ASL data. The motivation for doing so is to realise the benefits of the surface paradigm for perfusion measurement in the cortex via ASL without negatively impacting measurement in the subcortex. In turn, this could add to the understanding of a multitude of topics, from neurodegenerative disease to brain development. 

Although much of this work may find relevance for imaging of the human body in a broad sense, all of the investigation and discussion presented herein is framed in the specific context of perfusion measurement in the brain via ASL. When assessing the extent to which the conclusions of this work may be applied to other use cases, ASL may be assumed to represent any volumetric imaging technique that measures a signal in multiple tissues, whilst the brain (in particular the cortex) may be assumed to represent any organ that possesses a complex anatomy. PVE apply across a multitude of different volumetric imaging modalities, with some aspects that are unique to each. 

\section{Thesis outline}

Chapter \ref{lit_review_chapter} presents the background literature pertaining to this work. Briefly, these topics are basic neuroanatomy and the contrast mechanism of ASL (these being the organ and modality that are used to frame the investigations presented in subsequent chapters); kinetic modelling and parameter estimation from such data using Bayesian inference; the use of spatial priors to improve inference on noisy or under-determined systems; the origin and correction of partial volume effects; and finally the motivations, components and benefits of the surface paradigm for neuroimaging. 

Chapter \ref{pvec_chapter} investigates PVE and strategies that may be used to correct for them. A detailed discussion of how PVE arise, along with demonstrations of their impact upon imaging data, is followed by a series of experiments investigating the performance of correction strategies under different scenarios. The conclusion of this is a set of principles for analysis pipelines that maximise the chances of performing successful correction. 

Chapter \ref{tob_pv_chapter} details the development of a surface-based method for estimating partial volumes in the brain. This is evaluated and compared to an existing volumetric method using both simulation and \textit{in-vivo} data with encouraging results. Whilst this is useful as a standalone piece of work, it is better understood as one of two building blocks for the work introduced in chapter \ref{svb_chapter}.  

Chapter \ref{projection_chapter} details the development of a framework for projecting data onto the cortical surface and vice-versa. This is the other key building block for the work introduced in chapter \ref{svb_chapter}. The framework differs substantially to existing methods because it has been designed for a specific use case; but to the extent it can be compared with existing methods, this has been done using simulated and \textit{in-vivo} data. 

Chapter \ref{svb_chapter} details the development of a method for performing performing combined surface and volumetric inference on data. Building upon the work of chapters \ref{tob_pv_chapter} and \ref{projection_chapter}, the objective of this approach is to frame the inference directly around anatomy, which in turn renders the conventional approach to partial volume correction obsolete. A calibration of certain aspects of this method are presented, alongside a more thorough evaluation on simulated ASL data. 

Finally, chapter \ref{future_work_chapter} summarises the conclusions that can be drawn from this work and sets out a number of questions that require further investigation. 



